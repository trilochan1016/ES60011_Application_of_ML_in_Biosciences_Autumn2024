{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJDNL8y8SozR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520\n",
      "\n",
      "Data types of each column:\n",
      "age           int64\n",
      "sex          object\n",
      "bmi         float64\n",
      "children      int64\n",
      "smoker       object\n",
      "region       object\n",
      "charges     float64\n",
      "dtype: object\n",
      "\n",
      "Summary statistics:\n",
      "               age          bmi     children       charges\n",
      "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
      "mean     39.207025    30.663397     1.094918  13270.422265\n",
      "std      14.049960     6.098187     1.205493  12110.011237\n",
      "min      18.000000    15.960000     0.000000   1121.873900\n",
      "25%      27.000000    26.296250     0.000000   4740.287150\n",
      "50%      39.000000    30.400000     1.000000   9382.033000\n",
      "75%      51.000000    34.693750     2.000000  16639.912515\n",
      "max      64.000000    53.130000     5.000000  63770.428010\n",
      "\n",
      "Checking for missing values:\n",
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after handling missing values:\n",
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "\n",
      "Encoding categorical variables...\n",
      "\n",
      "Data after encoding:\n",
      "   age  sex     bmi  children  smoker  region      charges\n",
      "0   19    0  27.900         0       1       3  16884.92400\n",
      "1   18    1  33.770         1       0       2   1725.55230\n",
      "2   28    1  33.000         3       0       2   4449.46200\n",
      "3   33    1  22.705         0       0       1  21984.47061\n",
      "4   32    1  28.880         0       0       1   3866.85520\n",
      "\n",
      "Shape of X (features): (1338, 6)\n",
      "Shape of y (target): (1338,)\n",
      "\n",
      "Processed data saved to ./processed_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "filepath = './data_insurance.csv'  # Ensure this file is in your working directory\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "# 1. Explore the Data\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "print(\"\\nData types of each column:\")\n",
    "print(data.dtypes)\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# 2. Handle Missing Data\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# For numerical columns, fill missing values with the column's mean\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_columns:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "# For categorical columns, fill missing values with the most frequent value\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "print(\"\\nDataset after handling missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 3. Convert Categorical Variables\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "\n",
    "# Encode 'sex' and 'smoker' using Label Encoding\n",
    "label_encoders = {}  # Dictionary to store label encoders for reference\n",
    "for column in ['sex', 'smoker']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Encode 'region' using Label Encoding (assigns numeric labels to categories)\n",
    "region_le = LabelEncoder()\n",
    "data['region'] = region_le.fit_transform(data['region'])\n",
    "\n",
    "print(\"\\nData after encoding:\")\n",
    "print(data.head())\n",
    "\n",
    "# 4. Define Features and Target\n",
    "X = data.drop(columns=['charges']).values  # Independent variables\n",
    "y = data['charges'].values                 # Dependent variable\n",
    "\n",
    "print(\"\\nShape of X (features):\", X.shape)\n",
    "print(\"Shape of y (target):\", y.shape)\n",
    "\n",
    "# Save processed data if needed\n",
    "processed_filepath = './processed_data.csv'\n",
    "data.to_csv(processed_filepath, index=False)\n",
    "print(f\"\\nProcessed data saved to {processed_filepath}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "mnRd0p8LtRJ5"
   },
   "outputs": [],
   "source": [
    "# def random_feature_selection(X):\n",
    "#     X_new = None\n",
    "#     np.random.seed(48)\n",
    "#     r = np.random.randint(3, 7)\n",
    "#     X_new = X[:, :r]\n",
    "#     return X_new\n",
    "    \n",
    "# X = random_feature_selection(X)\n",
    "# print(\"Shape of X: \",X.shape, \"Shape of y: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "LLmD1I3-SozT",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (1003, 6) Shape of y_train:  (1003,)\n",
      "Shape of X_test:  (335, 6) Shape of y_test:  (335,)\n"
     ]
    }
   ],
   "source": [
    "## Data scaling and train-test split\n",
    "\n",
    "def train_test_split(X, y, test_size=0.25, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    split_index = int(X.shape[0] * (1 - test_size))\n",
    "\n",
    "    train_indices = indices[:split_index]\n",
    "    test_indices = indices[split_index:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def min_max_scaler(X, feature_range=(0, 1)):\n",
    "    X_min = np.min(X, axis=0)\n",
    "    X_max = np.max(X, axis=0)\n",
    "\n",
    "    X_scaled = (X-X_min)/(X_max-X_min)\n",
    "\n",
    "    return X_scaled\n",
    "\n",
    "\n",
    "X = min_max_scaler(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(\"Shape of X_train: \",X_train.shape, \"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of X_test: \",X_test.shape, \"Shape of y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "t6GqZMlYSozV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_function(X, y, w, b):\n",
    "    # number of training examples\n",
    "    m = X.shape[0]\n",
    "    y_matrix = y.reshape((m,1))\n",
    "    predictions = np.dot(X, w.T) + b\n",
    "    column_loss_vector = (predictions - y_matrix)\n",
    "    square_loss_vector = np.square(column_loss_vector)\n",
    "    loss = np.sum(square_loss_vector)/(2*m)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "do-IiCTZSozV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b):\n",
    "    # Number of training examples\n",
    "    m = X.shape[0]\n",
    "\n",
    "    dL_dw = None\n",
    "    dL_db = None\n",
    "\n",
    "    y_matrix = y.reshape((m,1))\n",
    "    predictions = np.dot(X, w.T) + b\n",
    "    errors = predictions - y_matrix\n",
    "    dL_dw = np.dot(errors.T, X) / m\n",
    "    dL_db = np.sum(errors) / m\n",
    "    return dL_dw, dL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "UHKldb3hSozV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## CODE REQUIRED ##\n",
    "\n",
    "def batch_gradient_descent(X, y, w_initial, b_initial, alpha, num_iters):\n",
    "    # number of training examples\n",
    "    m = X.shape[0]\n",
    "\n",
    "    # to store loss values for every iteation as a list and print loss value after every 100 iterations\n",
    "    loss_hist = []\n",
    "\n",
    "    # Initialize parameters\n",
    "    w = copy.deepcopy(w_initial) ## deepcopy is used so that the updates do not change the initial variable values\n",
    "    b = b_initial\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        dL_dw, dL_db = compute_gradient(X, y, w, b)\n",
    "        w = w - alpha * dL_dw\n",
    "        b = b - alpha * dL_db\n",
    "        loss = loss_function(X, y, w, b)\n",
    "        loss_hist.append(loss)\n",
    "        if i % 100000 == 0:\n",
    "            print(f\"Iteration {i}: Loss = {loss}\")\n",
    "           \n",
    "    return w, b, loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "Xd8QFReNDyGs"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    initial_w = None\n",
    "    initial_b = None\n",
    "    alpha = None\n",
    "\n",
    "    num_features = data.shape[1]\n",
    "    initial_w = np.random.randn(1, num_features-1)\n",
    "    initial_b = np.random.randn()\n",
    "    alpha = random.uniform(0.00001, 0.0001)\n",
    "\n",
    "    return initial_w,initial_b,alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "9rAYubtASozV",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 163631735.7618246\n",
      "Iteration 100000: Loss = 26808004.155384287\n",
      "Iteration 200000: Loss = 20620030.892464165\n",
      "Iteration 300000: Loss = 19299155.942987468\n",
      "Iteration 400000: Loss = 18853769.745274182\n",
      "Iteration 500000: Loss = 18631844.777550634\n",
      "Iteration 600000: Loss = 18496438.257335175\n",
      "Iteration 700000: Loss = 18405852.904831197\n",
      "Iteration 800000: Loss = 18342355.233809967\n",
      "Iteration 900000: Loss = 18296649.601447754\n",
      "Iteration 1000000: Loss = 18263226.662925463\n",
      "Iteration 1100000: Loss = 18238551.042311247\n",
      "Iteration 1200000: Loss = 18220227.58547107\n",
      "Iteration 1300000: Loss = 18206573.085888736\n",
      "Iteration 1400000: Loss = 18196375.981558323\n",
      "Iteration 1500000: Loss = 18188750.804476272\n",
      "Iteration 1600000: Loss = 18183044.220852945\n",
      "Iteration 1700000: Loss = 18178771.32590445\n",
      "Iteration 1800000: Loss = 18175570.911872488\n",
      "Iteration 1900000: Loss = 18173173.308027934\n",
      "Iteration 2000000: Loss = 18171376.902241956\n",
      "Iteration 2100000: Loss = 18170030.83306424\n",
      "Iteration 2200000: Loss = 18169022.152528938\n",
      "Iteration 2300000: Loss = 18168266.26850392\n",
      "Iteration 2400000: Loss = 18167699.81175308\n",
      "Iteration 2500000: Loss = 18167275.30458948\n",
      "Iteration 2600000: Loss = 18166957.172304146\n",
      "Iteration 2700000: Loss = 18166718.757370062\n",
      "Iteration 2800000: Loss = 18166540.083444253\n",
      "Iteration 2900000: Loss = 18166406.180456944\n",
      "Iteration 3000000: Loss = 18166305.829786874\n",
      "Iteration 3100000: Loss = 18166230.62405937\n",
      "Iteration 3200000: Loss = 18166174.26263162\n",
      "Iteration 3300000: Loss = 18166132.023658723\n",
      "Iteration 3400000: Loss = 18166100.368469547\n",
      "Iteration 3500000: Loss = 18166076.645086817\n",
      "Iteration 3600000: Loss = 18166058.866042513\n",
      "Iteration 3700000: Loss = 18166045.54186917\n",
      "Iteration 3800000: Loss = 18166035.556314792\n",
      "Iteration 3900000: Loss = 18166028.0728259\n",
      "Iteration 4000000: Loss = 18166022.46446339\n",
      "Iteration 4100000: Loss = 18166018.261379573\n",
      "Iteration 4200000: Loss = 18166015.111455865\n",
      "Iteration 4300000: Loss = 18166012.750803564\n",
      "Iteration 4400000: Loss = 18166010.981656153\n",
      "Iteration 4500000: Loss = 18166009.65580119\n",
      "Iteration 4600000: Loss = 18166008.662163578\n",
      "Iteration 4700000: Loss = 18166007.917500153\n",
      "Iteration 4800000: Loss = 18166007.35942585\n",
      "Iteration 4900000: Loss = 18166006.94118733\n",
      "Iteration 5000000: Loss = 18166006.627746165\n",
      "Iteration 5100000: Loss = 18166006.392843444\n",
      "Iteration 5200000: Loss = 18166006.21679992\n",
      "Iteration 5300000: Loss = 18166006.084867343\n",
      "Iteration 5400000: Loss = 18166005.985992897\n",
      "Iteration 5500000: Loss = 18166005.911893263\n",
      "Iteration 5600000: Loss = 18166005.85636065\n",
      "Iteration 5700000: Loss = 18166005.81474276\n",
      "Iteration 5800000: Loss = 18166005.783552997\n",
      "Iteration 5900000: Loss = 18166005.760178402\n",
      "Iteration 6000000: Loss = 18166005.742660742\n",
      "Iteration 6100000: Loss = 18166005.729532458\n",
      "Iteration 6200000: Loss = 18166005.7196937\n",
      "Iteration 6300000: Loss = 18166005.712320227\n",
      "Iteration 6400000: Loss = 18166005.706794314\n",
      "Iteration 6500000: Loss = 18166005.70265302\n",
      "Iteration 6600000: Loss = 18166005.6995494\n",
      "Iteration 6700000: Loss = 18166005.697223455\n",
      "Iteration 6800000: Loss = 18166005.695480317\n",
      "Iteration 6900000: Loss = 18166005.694173947\n",
      "Iteration 7000000: Loss = 18166005.693194922\n",
      "Iteration 7100000: Loss = 18166005.692461208\n",
      "Iteration 7200000: Loss = 18166005.691911336\n",
      "Iteration 7300000: Loss = 18166005.691499244\n",
      "Iteration 7400000: Loss = 18166005.691190414\n",
      "Iteration 7500000: Loss = 18166005.69095896\n",
      "Iteration 7600000: Loss = 18166005.69078551\n",
      "Iteration 7700000: Loss = 18166005.69065551\n",
      "Iteration 7800000: Loss = 18166005.690558095\n",
      "Iteration 7900000: Loss = 18166005.69048508\n",
      "Iteration 8000000: Loss = 18166005.69043036\n",
      "Iteration 8100000: Loss = 18166005.690389358\n",
      "Iteration 8200000: Loss = 18166005.690358628\n",
      "Iteration 8300000: Loss = 18166005.690335594\n",
      "Iteration 8400000: Loss = 18166005.69031834\n",
      "Iteration 8500000: Loss = 18166005.6903054\n",
      "Iteration 8600000: Loss = 18166005.690295707\n",
      "Iteration 8700000: Loss = 18166005.69028844\n",
      "Iteration 8800000: Loss = 18166005.690282997\n",
      "Iteration 8900000: Loss = 18166005.690278918\n",
      "Iteration 9000000: Loss = 18166005.69027586\n",
      "Iteration 9100000: Loss = 18166005.690273564\n",
      "Iteration 9200000: Loss = 18166005.69027185\n",
      "Iteration 9300000: Loss = 18166005.690270565\n",
      "Iteration 9400000: Loss = 18166005.690269597\n",
      "Iteration 9500000: Loss = 18166005.690268878\n",
      "Iteration 9600000: Loss = 18166005.690268338\n",
      "Iteration 9700000: Loss = 18166005.690267924\n",
      "Iteration 9800000: Loss = 18166005.690267622\n",
      "Iteration 9900000: Loss = 18166005.690267395\n",
      "Updated w:  [[ 1.21673693e+04 -1.20351349e-01  1.19668772e+04  2.69037864e+03\n",
      "   2.36933926e+04 -1.14582132e+03]]\n",
      "Updated b:  -2022.8636397640532\n"
     ]
    }
   ],
   "source": [
    "# initialize the parameters and hyperparameter\n",
    "initial_w, initial_b, alpha = initialize_parameters()\n",
    "\n",
    "# number of iterations\n",
    "num_iters = 10000000\n",
    "\n",
    "w,b,loss_hist = batch_gradient_descent(X_train,y_train,initial_w,initial_b,alpha,num_iters)\n",
    "print(\"Updated w: \",w)\n",
    "print(\"Updated b: \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "UIXb7sSvSozW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error:  18166005.690267228 , Test Error:  18624397.511475693\n"
     ]
    }
   ],
   "source": [
    "## Train and Test error computation\n",
    "train_error = loss_function(X_train,y_train,w,b)\n",
    "test_error = loss_function(X_test,y_test,w,b)\n",
    "print(\"Train Error: \",train_error, \", Test Error: \",test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "DW4bue0oSozW"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHACAYAAABeV0mSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA58klEQVR4nO3de3QU9d3H8c9uLhsgJIBASHAlAkVEIEQoiEhFG6VoI5RaqHgAQeFBoVVSWqEoN4UgFQ5VUB5RLvahRUuBWqFQjAJeqFzT0kLlkkCikECkuSIb2J3nD8hqTIBsmN3Jbt6vc+aYnf3NzndHJB9/lxmbYRiGAAAAQoTd6gIAAADMRLgBAAAhhXADAABCCuEGAACEFMINAAAIKYQbAAAQUgg3AAAgpBBuAABASCHcAACAkEK4AQAAIaVeh5vt27crNTVVCQkJstlsWr9+vc+fsXnzZt12221q3LixWrRooR//+Mc6duyY6bUCAICaqdfhpqysTElJSVq8eHGtjs/OztbAgQN19913KzMzU5s3b1ZBQYEGDx5scqUAAKCmbDw48yKbzaZ169Zp0KBB3n0ul0tTp07VH/7wBxUWFqpz58564YUX1K9fP0nSmjVr9NBDD8nlcsluv5gT//KXv2jgwIFyuVyKiIiw4JsAAFC/1euem6uZMGGCduzYodWrV+uf//ynfvKTn+gHP/iBDh8+LEnq3r277Ha7li9fLrfbraKiIv3ud79TSkoKwQYAAIvQc3PJt3tucnJy1LZtW+Xk5CghIcHbLiUlRT179tScOXMkSdu2bdOQIUP05Zdfyu12q3fv3tq4caOaNGliwbcAAAD03FzG/v375Xa71aFDB0VHR3u3bdu26ejRo5KkvLw8jRkzRiNHjtSuXbu0bds2RUZG6sEHHxSZEQAAa4RbXUBdVVpaqrCwMO3Zs0dhYWGV3ouOjpYkLV68WLGxsZo3b573vf/7v/+T0+nUp59+qttuuy2gNQMAAMLNZSUnJ8vtduvUqVPq27dvtW3Onj3rnUhcoSIIeTwev9cIAACqqtfDUqWlpcrMzFRmZqaki0u7MzMzlZOTow4dOujhhx/WiBEjtHbtWmVnZ2vnzp1KT0/Xhg0bJEn333+/du3apVmzZunw4cPau3evRo0apTZt2ig5OdnCbwYAQP1VrycUb926VXfddVeV/SNHjtSKFSt0/vx5Pf/883rzzTf1xRdfqHnz5rrttts0c+ZMdenSRZK0evVqzZs3T4cOHVLDhg3Vu3dvvfDCC+rYsWOgvw4AAFA9DzcAACD01OthKQAAEHoINwAAIKTUu9VSHo9HJ06cUOPGjWWz2awuBwAA1IBhGCopKVFCQkKVlcrfVu/CzYkTJ+R0Oq0uAwAA1EJubq6uv/76K7apd+GmcePGki5enJiYGIurAQAANVFcXCyn0+n9PX4l9S7cVAxFxcTEEG4AAAgyNZlSwoRiAAAQUgg3AAAgpBBuAABASCHcAACAkEK4AQAAIYVwAwAAQgrhBgAAhBTCDQAACCmEGwAAEFIINwAAIKQQbgAAQEgh3AAAgJBS7x6c6S9uj6GTRV9Jkq5v2tDiagAAqL8INyb5ssylO174QHablJV+v9XlAABQbzEsBQAAQgrhxmSG1QUAAFDPEW5MYpPN6hIAAIAINwAAIMRYGm62b9+u1NRUJSQkyGazaf369Vc9xuVyaerUqWrTpo0cDocSExO1bNky/xdbQwbjUgAAWMrS1VJlZWVKSkrS6NGjNXjw4BodM2TIEOXn5+uNN95Q+/btdfLkSXk8Hj9XenU2RqUAAKgTLA03AwYM0IABA2rcftOmTdq2bZuysrLUrFkzSVJiYqKfqgMAAMEoqObcvPPOO+rRo4fmzZun1q1bq0OHDpo0aZK++uqryx7jcrlUXFxcaQMAAKErqG7il5WVpY8++khRUVFat26dCgoK9MQTT+jLL7/U8uXLqz0mPT1dM2fO9HttjEoBAFA3BFXPjcfjkc1m06pVq9SzZ0/dd999WrBggVauXHnZ3pspU6aoqKjIu+Xm5ga4agAAEEhB1XMTHx+v1q1bKzY21rvv5ptvlmEY+vzzz/Wd73ynyjEOh0MOhyOQZcowDNmYYQwAgCWCquemT58+OnHihEpLS737Dh06JLvdruuvv97CykSYAQCgjrA03JSWliozM1OZmZmSpOzsbGVmZionJ0fSxSGlESNGeNsPGzZM1113nUaNGqUDBw5o+/bt+uUvf6nRo0erQYMGVnwFAABQx1gabnbv3q3k5GQlJydLktLS0pScnKxp06ZJkk6ePOkNOpIUHR2tLVu2qLCwUD169NDDDz+s1NRUvfTSS5bUfzncyA8AAOtYOuemX79+Mq6QBFasWFFlX8eOHbVlyxY/VlU7DEoBAFA3BNWcm2BBxw0AANYh3JiE+cQAANQNhBsAABBSCDd+cKV5RAAAwL8INyaxMaUYAIA6gXADAABCCuHGDxiUAgDAOoQbszAqBQBAnUC4AQAAIYVw4wcslgIAwDqEG5NwEz8AAOoGwg0AAAgphBs/MFgvBQCAZQg3JmFUCgCAuoFwAwAAQgrhxg9YLQUAgHUINyaxsVwKAIA6gXADAABCCuEGAACEFMKNSRiUAgCgbiDc+AETigEAsA7hxiTMJwYAoG4g3AAAgJBCuPEDHr8AAIB1CDcmsTGlGACAOoFwAwAAQgrhxg9YLQUAgHUINyZhtRQAAHUD4QYAAIQUwo0fMCoFAIB1CDcAACCkEG4AAEBIIdz4gcFyKQAALEO4MQmrpQAAqBsINwAAIKRYGm62b9+u1NRUJSQkyGazaf369TU+9uOPP1Z4eLi6devmt/pqi0EpAACsY2m4KSsrU1JSkhYvXuzTcYWFhRoxYoS+//3v+6ky3/FsKQAA6oZwK08+YMAADRgwwOfjxo0bp2HDhiksLMyn3h4AABD6gm7OzfLly5WVlaXp06dbXcplsVgKAADrWNpz46vDhw9r8uTJ+vDDDxUeXrPSXS6XXC6X93VxcbFfamO1FAAAdUPQ9Ny43W4NGzZMM2fOVIcOHWp8XHp6umJjY72b0+n0Y5WX0HMDAIBlgibclJSUaPfu3ZowYYLCw8MVHh6uWbNm6R//+IfCw8P1/vvvV3vclClTVFRU5N1yc3P9Uh8dNwAA1A1BMywVExOj/fv3V9r3yiuv6P3339eaNWt04403Vnucw+GQw+EIRIkAAKAOsDTclJaW6siRI97X2dnZyszMVLNmzXTDDTdoypQp+uKLL/Tmm2/Kbrerc+fOlY5v2bKloqKiquy3msG4FAAAlrE03OzevVt33XWX93VaWpokaeTIkVqxYoVOnjypnJwcq8rziY0ZxQAA1Ak2o5495bG4uFixsbEqKipSTEyMaZ/r9hhq9+uNkqTMafeoScNI0z4bAID6zpff30EzoTiY1K+4CABA3UK4MQmDUgAA1A2EGwAAEFIIN37AqBQAANYh3JiExVIAANQNhBsAABBSCDd+UM9W1wMAUKcQbkzCTfwAAKgbCDcAACCkEG78gEEpAACsQ7gBAAAhhXDjB8wnBgDAOoQbEzGnGAAA6xFuAABASCHc+IHBlGIAACxDuDERo1IAAFiPcAMAAEIK4cYfGJUCAMAyhBsT8QgGAACsR7gBAAAhhXDjB4xKAQBgHcKNiRiUAgDAeoQbAAAQUgg3fsCzpQAAsA7hxkQslgIAwHqEGwAAEFIIN37As6UAALAO4cZENtZLAQBgOcINAAAIKYQbP2C1FAAA1iHcmIlRKQAALEe48QM6bgAAsA7hxkR03AAAYD3CDQAACCmEGz8wmFEMAIBlLA0327dvV2pqqhISEmSz2bR+/fortl+7dq3uuecetWjRQjExMerdu7c2b94cmGJrgMcvAABgPUvDTVlZmZKSkrR48eIatd++fbvuuecebdy4UXv27NFdd92l1NRU7du3z8+VAgCAYBFu5ckHDBigAQMG1Lj9woULK72eM2eO/vznP+svf/mLkpOTTa6u9hiVAgDAOkE958bj8aikpETNmjWzuhRJPH4BAIC6wNKem2v14osvqrS0VEOGDLlsG5fLJZfL5X1dXFwciNIAAIBFgrbn5ve//71mzpypt99+Wy1btrxsu/T0dMXGxno3p9MZwCoBAECgBWW4Wb16tR577DG9/fbbSklJuWLbKVOmqKioyLvl5ub6rS5WSwEAYL2gG5b6wx/+oNGjR2v16tW6//77r9re4XDI4XAEoDIAAFAXWBpuSktLdeTIEe/r7OxsZWZmqlmzZrrhhhs0ZcoUffHFF3rzzTclXRyKGjlypH7729+qV69eysvLkyQ1aNBAsbGxlnyH6rBaCgAA61g6LLV7924lJyd7l3GnpaUpOTlZ06ZNkySdPHlSOTk53vavvfaaLly4oPHjxys+Pt67Pfnkk5bU/22MSgEAYD1Le2769et3xUcVrFixotLrrVu3+rcgAAAQ9IJyQnFdZ4hxKQAArEK4MZGN5VIAAFiOcAMAAEIK4cYPWC0FAIB1CDcmYlAKAADrEW78gI4bAACsQ7gxE103AABYjnADAABCCuHGD650Y0IAAOBfhBsTMSoFAID1CDcAACCkEG78gEEpAACsQ7gxEY9fAADAeoQbAAAQUgg3fsBiKQAArEO4MRGjUgAAWI9wAwAAQkp4bQ7yeDw6cuSITp06JY/HU+m9733ve6YUFtwYlwIAwCo+h5u///3vGjZsmI4fP17lTrw2m01ut9u04oINo1IAAFjP53Azbtw49ejRQxs2bFB8fDzLnwEAQJ3ic7g5fPiw1qxZo/bt2/ujnpDAaikAAKzj84TiXr166ciRI/6oJejRiwUAgPV87rn52c9+pl/84hfKy8tTly5dFBERUen9rl27mlZcsKLjBgAA6/gcbn784x9LkkaPHu3dZ7PZZBgGE4qtLgAAAPgebrKzs/1RBwAAgCl8Djdt2rTxRx0hhQnFAABYp1Y38Tt69KgWLlyogwcPSpI6deqkJ598Uu3atTO1uGDDfGIAAKzn82qpzZs3q1OnTtq5c6e6du2qrl276tNPP9Utt9yiLVu2+KNGAACAGvO552by5MmaOHGi5s6dW2X/008/rXvuuce04oKVwXopAAAs43PPzcGDB/Xoo49W2T969GgdOHDAlKKCF+NSAABYzedw06JFC2VmZlbZn5mZqZYtW5pREwAAQK35PCw1ZswYjR07VllZWbr99tslSR9//LFeeOEFpaWlmV5gMGK1FAAA1vE53Dz77LNq3Lix5s+frylTpkiSEhISNGPGDP385z83vcBgwmopAACs53O4sdlsmjhxoiZOnKiSkhJJUuPGjU0vDAAAoDZqdZ+bCoSa6jEsBQCAdWo0ofjWW2/Vf//7X0lScnKybr311stuvti+fbtSU1OVkJAgm82m9evXX/WYrVu36tZbb5XD4VD79u21YsUKn87pT4xKAQBgvRr13AwcOFAOh8P7s82kySVlZWVKSkrS6NGjNXjw4Ku2z87O1v33369x48Zp1apVysjI0GOPPab4+Hj179/flJoAAEBwsxlG3RhEsdlsWrdunQYNGnTZNk8//bQ2bNigf/3rX959P/3pT1VYWKhNmzbV6DzFxcWKjY1VUVGRYmJirrXsSnrOfk+nSlza8PM7dEtCrKmfDQBAfebL72+f73PTtm1bffnll1X2FxYWqm3btr5+nE927NihlJSUSvv69++vHTt2+PW8NcVqKQAArOfzhOJjx47J7XZX2e9yufT555+bUtTl5OXlKS4urtK+uLg4FRcX66uvvlKDBg2qrcvlcnlfFxcX+7VGAABgrRqHm3feecf78+bNmxUb+/Wwi9vtVkZGhm688UZzqzNBenq6Zs6cGdBz1o2BPgAA6qcah5uKuTA2m00jR46s9F5ERIQSExM1f/58U4v7tlatWik/P7/Svvz8fMXExFTbayNJU6ZMqXTn5OLiYjmdTr/UZ2O9FAAAlqtxuPF4PJKkG2+8Ubt27VLz5s39VtTl9O7dWxs3bqy0b8uWLerdu/dlj3E4HN6VXgAAIPT5PKE4OzvbtGBTWlqqzMxM74M4s7OzlZmZqZycHEkXe11GjBjhbT9u3DhlZWXpV7/6lf7zn//olVde0dtvv62JEyeaUs+1YkIxAADW8znc/PznP9dLL71UZf+iRYv01FNP+fRZu3fvVnJyspKTkyVJaWlpSk5O1rRp0yRJJ0+e9AYd6WKv0YYNG7RlyxYlJSVp/vz5ev3117nHDQAA8PL5PjetW7fWO++8o+7du1fav3fvXj3wwAN+XzF1rfx5n5ve6Rk6WXROf5lwh7pcz31uAAAwi1/vc/Pll19WWilVISYmRgUFBb5+XEhhVAoAAOv5HG7at29f7d2A//rXv/r9Jn4AAABX4/NN/NLS0jRhwgSdPn1ad999tyQpIyND8+fP18KFC82uLygZ4kY3AABYxedwM3r0aLlcLs2ePVvPPfecJCkxMVGvvvpqpZVN9ZFZDxQFAAC153O4kaTHH39cjz/+uE6fPq0GDRooOjra7LoAAABqpVbhpkKLFi3MqiOk8PgFAACs4/OE4vz8fA0fPlwJCQkKDw9XWFhYpQ0AAMBKPvfcPPLII8rJydGzzz6r+Ph45pkAAIA6xedw89FHH+nDDz9Ut27d/FBOaGBUCgAA6/g8LOV0OuXjTY3rDTqxAACwns/hZuHChZo8ebKOHTvmh3IAAACujc/DUkOHDtXZs2fVrl07NWzYUBEREZXeP3PmjGnFBSt6tgAAsI7P4Ya7EF8ew1IAAFjP53AzcuRIf9QRUui3AQDAOj6Hm5ycnCu+f8MNN9S6mGBn47ngAABYzudwk5iYeMV727jd7msqCAAA4Fr4HG727dtX6fX58+e1b98+LViwQLNnzzatsGDGfGIAAKzjc7hJSkqqsq9Hjx5KSEjQb37zGw0ePNiUwoIRE4oBALCez/e5uZybbrpJu3btMuvjAAAAasXnnpvi4uJKrw3D0MmTJzVjxgx95zvfMa2w4Ma4FAAAVvE53DRp0qTKhGLDMOR0OrV69WrTCgtGjEoBAGA9n8PNBx98UOm13W5XixYt1L59e4WH+/xxAAAApqpRGrn11luVkZGhpk2batu2bZo0aZIaNmzo79qCFqulAACwTo0mFB88eFBlZWWSpJkzZ3p/RmVXuv8PAAAIjBr13HTr1k2jRo3SHXfcIcMw9Jvf/EbR0dHVtp02bZqpBQIAAPiiRuFmxYoVmj59ut59913ZbDb99a9/rXZ+jc1mI9yItVIAAFipRuHmpptu8q6EstvtysjIUMuWLf1aWDBiUAoAAOv5vLzJ4/H4ow4AAABTmHaHYnyN1VIAAFiHcGOiisVSBukGAADLEG5MVLEU3EO2AQDAMoQbE1VMKDZYLwUAgGV8Dje5ubn6/PPPva937typp556Sq+99pqphQUj29fpBgAAWMTncDNs2DDv86Xy8vJ0zz33aOfOnZo6dapmzZpleoHBxM6wFAAAlvM53PzrX/9Sz549JUlvv/22OnfurE8++USrVq3SihUrzK4vKDEsBQCAdXwON+fPn5fD4ZAkvffee3rggQckSR07dtTJkyfNrS7IVEwoZrEUAADW8Tnc3HLLLVqyZIk+/PBDbdmyRT/4wQ8kSSdOnNB1111XqyIWL16sxMRERUVFqVevXtq5c+cV2y9cuFA33XSTGjRoIKfTqYkTJ+rcuXO1OreZmHIDAID1fA43L7zwgv73f/9X/fr100MPPaSkpCRJ0jvvvOMdrvLFW2+9pbS0NE2fPl179+5VUlKS+vfvr1OnTlXb/ve//70mT56s6dOn6+DBg3rjjTf01ltv6de//rXP5zab/dLV9NB1AwCAZXx+/EK/fv1UUFCg4uJiNW3a1Lt/7Nixatiwoc8FLFiwQGPGjNGoUaMkSUuWLNGGDRu0bNkyTZ48uUr7Tz75RH369NGwYcMkSYmJiXrooYf06aef+nxus9kq+m7INgAAWMbnnpuvvvpKLpfLG2yOHz+uhQsX6rPPPvP5YZrl5eXas2ePUlJSvi7IbldKSop27NhR7TG333679uzZ4x26ysrK0saNG3XfffdV297lcqm4uLjS5i/eOxSTbgAAsIzP4WbgwIF68803JUmFhYXq1auX5s+fr0GDBunVV1/16bMKCgrkdrsVFxdXaX9cXJzy8vKqPWbYsGGaNWuW7rjjDkVERKhdu3bq16/fZYel0tPTFRsb692cTqdPNfrCO+eGbAMAgGV8Djd79+5V3759JUlr1qxRXFycjh8/rjfffFMvvfSS6QV+29atWzVnzhy98sor2rt3r9auXasNGzboueeeq7b9lClTVFRU5N1yc3P9VhuPXwAAwHo+z7k5e/asGjduLEn629/+psGDB8tut+u2227T8ePHffqs5s2bKywsTPn5+ZX25+fnq1WrVtUe8+yzz2r48OF67LHHJEldunRRWVmZxo4dq6lTp8pur5zXHA6Hd+m6v/HgTAAArOdzz0379u21fv165ebmavPmzbr33nslSadOnVJMTIxPnxUZGanu3bsrIyPDu8/j8SgjI0O9e/eu9pizZ89WCTBhYWGSrA8VLAUHAMB6PoebadOmadKkSUpMTFTPnj29IeRvf/ubkpOTfS4gLS1NS5cu1cqVK3Xw4EE9/vjjKisr866eGjFihKZMmeJtn5qaqldffVWrV69Wdna2tmzZomeffVapqanekGMVbuIHAID1fB6WevDBB3XHHXfo5MmT3nvcSNL3v/99/ehHP/K5gKFDh+r06dOaNm2a8vLy1K1bN23atMk7yTgnJ6dST80zzzwjm82mZ555Rl988YVatGih1NRUzZ492+dzm83OsBQAAJazGdfwm7ji6eDXX3+9aQX5W3FxsWJjY1VUVOTzMNrVDFmyQzuPndErD9+q+7rEm/rZAADUZ778/vZ5WMrj8WjWrFmKjY1VmzZt1KZNGzVp0kTPPfecPB5PrYsOCd6eG2vLAACgPvN5WGrq1Kl64403NHfuXPXp00eS9NFHH2nGjBk6d+5cnRgeskrFhGIevwAAgHV8DjcrV67U66+/7n0auCR17dpVrVu31hNPPFGvw429YkKxxXUAAFCf+TwsdebMGXXs2LHK/o4dO+rMmTOmFBWsuM8NAADW8zncJCUladGiRVX2L1q0qNLqqfqoItwAAADr+DwsNW/ePN1///167733vPe42bFjh3Jzc7Vx40bTCwwmFU8FZ84NAADW8bnn5s4779ShQ4f0ox/9SIWFhSosLNTgwYP12WefeZ85VV/ZWC0FAIDlfO65kaSEhIQqE4c///xzjR07Vq+99pophQUj7lAMAID1fO65uZwvv/xSb7zxhlkfF5R4thQAANYzLdzg62Ep5twAAGAdwo2J7N5JN9bWAQBAfUa4MdHXw1KkGwAArFLjCcWDBw++4vuFhYXXWkvQY7UUAADWq3G4iY2Nver7I0aMuOaCglvFfW4sLgMAgHqsxuFm+fLl/qwjJNi9U25INwAAWIU5NyZiWAoAAOsRbkxU8fgFHpwJAIB1CDcmYiU4AADWI9yYyM7jFwAAsBzhxkzeOTekGwAArEK4MVHFTfxYCg4AgHUINybyPhXc4joAAKjPCDcmsjMsBQCA5Qg3JrJdvQkAAPAzwo2JKoalPPTcAABgGcKNibxPBSfbAABgGcKNiZhQDACA9Qg3JuLZUgAAWI9wY6Kv73NDugEAwCqEGxPZWC4FAIDlCDcm+vrZUvTcAABgFcKNiZhzAwCA9Qg3pqq4z43FZQAAUI8Rbkzk7blhMTgAAJYh3JgorOIOxXTdAABgmToRbhYvXqzExERFRUWpV69e2rlz5xXbFxYWavz48YqPj5fD4VCHDh20cePGAFV7eWGXnpzpZtINAACWCbe6gLfeektpaWlasmSJevXqpYULF6p///767LPP1LJlyyrty8vLdc8996hly5Zas2aNWrdurePHj6tJkyaBL/5bvOHGY3EhAADUY5aHmwULFmjMmDEaNWqUJGnJkiXasGGDli1bpsmTJ1dpv2zZMp05c0affPKJIiIiJEmJiYmBLPmywr3hhnQDAIBVLB2WKi8v1549e5SSkuLdZ7fblZKSoh07dlR7zDvvvKPevXtr/PjxiouLU+fOnTVnzhy53e5q27tcLhUXF1fa/MV+KdxcYM4NAACWsTTcFBQUyO12Ky4urtL+uLg45eXlVXtMVlaW1qxZI7fbrY0bN+rZZ5/V/Pnz9fzzz1fbPj09XbGxsd7N6XSa/j0qVPTcMKEYAADr1IkJxb7weDxq2bKlXnvtNXXv3l1Dhw7V1KlTtWTJkmrbT5kyRUVFRd4tNzfXb7WF0XMDAIDlLJ1z07x5c4WFhSk/P7/S/vz8fLVq1araY+Lj4xUREaGwsDDvvptvvll5eXkqLy9XZGRkpfYOh0MOh8P84qvx9Zwbwg0AAFaxtOcmMjJS3bt3V0ZGhnefx+NRRkaGevfuXe0xffr00ZEjR+T5xqTdQ4cOKT4+vkqwCTTm3AAAYD3Lh6XS0tK0dOlSrVy5UgcPHtTjjz+usrIy7+qpESNGaMqUKd72jz/+uM6cOaMnn3xShw4d0oYNGzRnzhyNHz/eqq/gxZwbAACsZ/lS8KFDh+r06dOaNm2a8vLy1K1bN23atMk7yTgnJ0d2+9cZzOl0avPmzZo4caK6du2q1q1b68knn9TTTz9t1VfwCrtUJz03AABYx2YY9et2usXFxYqNjVVRUZFiYmJM/ewVH2drxl8O6P4u8Vr88K2mfjYAAPWZL7+/LR+WCiVhYRU9N9zEDwAAqxBuTBTO4xcAALAc4cZEYTx+AQAAyxFuTBRmYyk4AABWI9yYKDzs0lLw+jVHGwCAOoVwYyLv4xfchBsAAKxCuDFRxbAUj18AAMA6hBsT8eBMAACsR7gxUcWcG3puAACwDuHGRBGXbuJ3nhvdAABgGcKNiRzhYZKk8guEGwAArEK4MVFk+MXL6SLcAABgGcKNiRzecOO2uBIAAOovwo2JHPTcAABgOcKNiRiWAgDAeoQbE31zQrHBIxgAALAE4cZEjoivL2c5y8EBALAE4cZEkWFfX06GpgAAsAbhxkQVE4ol7nUDAIBVCDcmstlsTCoGAMBihBuTeZeDn+deNwAAWIFwY7KKcMOEYgAArEG4MVnFcnDXecINAABWINyYjLsUAwBgLcKNyaIiLvbcfMWcGwAALEG4MVnDyIvh5qzrgsWVAABQPxFuTNagItyU03MDAIAVCDcm8/bcMCwFAIAlCDcmaxQZLkn6qpxhKQAArEC4MVnFsFSZi54bAACsQLgxWcWwFKulAACwBuHGZA0uDUudZVgKAABLEG5M1ojVUgAAWIpwY7Kv73NDuAEAwAqEG5N5h6WYcwMAgCXqRLhZvHixEhMTFRUVpV69emnnzp01Om716tWy2WwaNGiQfwv0gXdCMXNuAACwhOXh5q233lJaWpqmT5+uvXv3KikpSf3799epU6eueNyxY8c0adIk9e3bN0CV1gx3KAYAwFqWh5sFCxZozJgxGjVqlDp16qQlS5aoYcOGWrZs2WWPcbvdevjhhzVz5ky1bds2gNVeXSPvainCDQAAVrA03JSXl2vPnj1KSUnx7rPb7UpJSdGOHTsue9ysWbPUsmVLPfroo1c9h8vlUnFxcaXNn7wTihmWAgDAEpaGm4KCArndbsXFxVXaHxcXp7y8vGqP+eijj/TGG29o6dKlNTpHenq6YmNjvZvT6bzmuq+E1VIAAFjL8mEpX5SUlGj48OFaunSpmjdvXqNjpkyZoqKiIu+Wm5vr1xqjoy4OS5WWX5DHY/j1XAAAoKpwK0/evHlzhYWFKT8/v9L+/Px8tWrVqkr7o0eP6tixY0pNTfXu83g8kqTw8HB99tlnateuXaVjHA6HHA6HH6qvXkxUhCTJMC4GnIrXAAAgMCztuYmMjFT37t2VkZHh3efxeJSRkaHevXtXad+xY0ft379fmZmZ3u2BBx7QXXfdpczMTL8POdVEVESYIsMuXtaSc8y7AQAg0CztuZGktLQ0jRw5Uj169FDPnj21cOFClZWVadSoUZKkESNGqHXr1kpPT1dUVJQ6d+5c6fgmTZpIUpX9VoppEK6C0nIVf3VerZs0sLocAADqFcvDzdChQ3X69GlNmzZNeXl56tatmzZt2uSdZJyTkyO7PaimBqlxVIQKSsvpuQEAwAI2wzDq1azX4uJixcbGqqioSDExMX45x8BFH+kfnxfp9RE9lNIp7uoHAACAK/Ll93dwdYkEicaXJhGXuM5bXAkAAPUP4cYPYhpcHO0r/ophKQAAAo1w4weNHZd6bs7RcwMAQKARbvzA23PDhGIAAAKOcOMH3jk39NwAABBwhBs/iImi5wYAAKsQbvwgtuHFnpvCs+UWVwIAQP1DuPGDZo0uPsvqy1LCDQAAgUa48YPrGkVKks6UEW4AAAg0wo0fNPtGuKlnN4AGAMByhBs/qAg3FzwGN/IDACDACDd+EBURpmjHxRVTX5a5LK4GAID6hXDjJ82YdwMAgCUIN35yXfTFcFPAiikAAAKKcOMnrJgCAMAahBs/ue7SvW5OlzDnBgCAQCLc+El8kyhJUl7xVxZXAgBA/UK48ZOE2AaSpBOF5yyuBACA+oVw4ycJTSrCDT03AAAEEuHGTyqGpU4UfsVdigEACCDCjZ9UDEuVlbtVfI67FAMAECiEGz9pEBmmpg0jJEknixiaAgAgUAg3fnR904aSpJwvz1pcCQAA9Qfhxo/atmgkSTp6usziSgAAqD8IN37UvkW0JOno6VKLKwEAoP4g3PhRu5aEGwAAAo1w40ftLvXcHDlVynJwAAAChHDjR4nNGyoizKaScxf0+X9ZMQUAQCAQbvzIER6mm+NjJEmZuYXWFgMAQD1BuPGzbs4mkgg3AAAECuHGzyrCzb6c/1pbCAAA9QThxs963thMkvSPz4tUeLbc4moAAAh9hBs/u75pQ3WIi5bbY2jbodNWlwMAQMgj3ATAXR1bSpI2/zvP4koAAAh9hJsAeCApQZK05UC+CkpdFlcDAEBoqxPhZvHixUpMTFRUVJR69eqlnTt3Xrbt0qVL1bdvXzVt2lRNmzZVSkrKFdvXBbckxCrJ2UTn3YZ+t+O41eUAABDSLA83b731ltLS0jR9+nTt3btXSUlJ6t+/v06dOlVt+61bt+qhhx7SBx98oB07dsjpdOree+/VF198EeDKfTOm742SpNc/zNKpknMWVwMAQOiyGRY/F6BXr1767ne/q0WLFkmSPB6PnE6nfvazn2ny5MlXPd7tdqtp06ZatGiRRowYcdX2xcXFio2NVVFRkWJiYq65/poyDEODXvlE/8gtVN/vNNeKUT0VZrcF7PwAAAQzX35/W9pzU15erj179iglJcW7z263KyUlRTt27KjRZ5w9e1bnz59Xs2bN/FWmKWw2m37zYFdFRdj14eEC/eLtTLkuuK0uCwCAkGNpuCkoKJDb7VZcXFyl/XFxccrLq9nKoqeffloJCQmVAtI3uVwuFRcXV9qs0iGusRYO7aZwu03rM09o0OJP9MmRAh6qCQCAiSyfc3Mt5s6dq9WrV2vdunWKioqqtk16erpiY2O9m9PpDHCVlf2gc7yWjuyhZo0idfBksYa9/qkG/PZDLXr/sPYc/y+9OQAAXCNL59yUl5erYcOGWrNmjQYNGuTdP3LkSBUWFurPf/7zZY998cUX9fzzz+u9995Tjx49LtvO5XLJ5fp6+XVxcbGcTmfA59x82+kSlxa9f1h/2JWr8gse7/7IcLvaNm+kti0aKfG6Ropv0kAtoh1q0dihlo0datIwQo0iw2Vnvg4AoB7xZc5NnZhQ3LNnT7388suSLk4ovuGGGzRhwoTLTiieN2+eZs+erc2bN+u2227z6XxWTSi+nKKz57X533nacjBfe4//V1+WXf0RDTabFB0ZruiocDWOCle0I1yNHOFyhIfJEWGXI9x+8edw+6XXl34OtyvMbvt6s9kqv7bbFG63yW6zKTzs0j/tdtntkt1mk00X5w7ZbLr0syR987XNu992ab++9brSz5f5jNq6lrh3DaeV7RrOfC3nDaZzAqhfwuw2xcc2MPUzffn9HW7qmWshLS1NI0eOVI8ePdSzZ08tXLhQZWVlGjVqlCRpxIgRat26tdLT0yVJL7zwgqZNm6bf//73SkxM9M7NiY6OVnR0tGXfo7ZiG0ZoyHedGvJdpwzDUO6Zr3T0dKmyCsp0rKBM+cXndLrUpdMlFzfXBY8MQypxXVCJ64JOFln9DQAAqKxlY4d2Tq1+LmwgWB5uhg4dqtOnT2vatGnKy8tTt27dtGnTJu8k45ycHNntX08NevXVV1VeXq4HH3yw0udMnz5dM2bMCGTpprPZbLrhuoa64bqGuqua9w3DkOuCRyXnLqjk3HmVui5c+vmCylwXVO72yHXeLdcFz6XNrfKKn89ffO02JLfHI7fH8G4XPIY8hqEL7kv/9BjyXNpf0cZjGDIkyZCMS7Vc/KdkyLj4T+PrOqu8p4r3v/n6G+0MQ9fSh3gt3Y/X0nl5beet7TmvoV7mrgMIAEeEtVN6LR+WCrS6NiwFAACuLmjucwMAAGA2wg0AAAgphBsAABBSCDcAACCkEG4AAEBIIdwAAICQQrgBAAAhhXADAABCCuEGAACEFMINAAAIKYQbAAAQUgg3AAAgpBBuAABASCHcAACAkBJudQGBZhiGpIuPTgcAAMGh4vd2xe/xK6l34aakpESS5HQ6La4EAAD4qqSkRLGxsVdsYzNqEoFCiMfj0YkTJ9S4cWPZbDZTP7u4uFhOp1O5ubmKiYkx9bPxNa5zYHCdA4PrHDhc68Dw13U2DEMlJSVKSEiQ3X7lWTX1rufGbrfr+uuv9+s5YmJi+A8nALjOgcF1Dgyuc+BwrQPDH9f5aj02FZhQDAAAQgrhBgAAhBTCjYkcDoemT58uh8NhdSkhjescGFznwOA6Bw7XOjDqwnWudxOKAQBAaKPnBgAAhBTCDQAACCmEGwAAEFIINz5avHixEhMTFRUVpV69emnnzp1XbP/HP/5RHTt2VFRUlLp06aKNGzcGqNLg5st1Xrp0qfr27aumTZuqadOmSklJueq/F1zk65/nCqtXr5bNZtOgQYP8W2CI8PU6FxYWavz48YqPj5fD4VCHDh34u6OGfL3WCxcu1E033aQGDRrI6XRq4sSJOnfuXICqDT7bt29XamqqEhISZLPZtH79+qses3XrVt16661yOBxq3769VqxY4fc6ZaDGVq9ebURGRhrLli0z/v3vfxtjxowxmjRpYuTn51fb/uOPPzbCwsKMefPmGQcOHDCeeeYZIyIiwti/f3+AKw8uvl7nYcOGGYsXLzb27dtnHDx40HjkkUeM2NhY4/PPPw9w5cHF1+tcITs722jdurXRt29fY+DAgYEpNoj5ep1dLpfRo0cP47777jM++ugjIzs729i6dauRmZkZ4MqDj6/XetWqVYbD4TBWrVplZGdnG5s3bzbi4+ONiRMnBrjy4LFx40Zj6tSpxtq1aw1Jxrp1667YPisry2jYsKGRlpZmHDhwwHj55ZeNsLAwY9OmTX6tk3Djg549exrjx4/3vna73UZCQoKRnp5ebfshQ4YY999/f6V9vXr1Mv7nf/7Hr3UGO1+v87dduHDBaNy4sbFy5Up/lRgSanOdL1y4YNx+++3G66+/bowcOZJwUwO+XudXX33VaNu2rVFeXh6oEkOGr9d6/Pjxxt13311pX1pamtGnTx+/1hkqahJufvWrXxm33HJLpX1Dhw41+vfv78fKDINhqRoqLy/Xnj17lJKS4t1nt9uVkpKiHTt2VHvMjh07KrWXpP79+1+2PWp3nb/t7NmzOn/+vJo1a+avMoNeba/zrFmz1LJlSz366KOBKDPo1eY6v/POO+rdu7fGjx+vuLg4de7cWXPmzJHb7Q5U2UGpNtf69ttv1549e7xDV1lZWdq4caPuu+++gNRcH1j1e7DePVuqtgoKCuR2uxUXF1dpf1xcnP7zn/9Ue0xeXl617fPy8vxWZ7CrzXX+tqeffloJCQlV/oPC12pznT/66CO98cYbyszMDECFoaE21zkrK0vvv/++Hn74YW3cuFFHjhzRE088ofPnz2v69OmBKDso1eZaDxs2TAUFBbrjjjtkGIYuXLigcePG6de//nUgSq4XLvd7sLi4WF999ZUaNGjgl/PSc4OQMnfuXK1evVrr1q1TVFSU1eWEjJKSEg0fPlxLly5V8+bNrS4npHk8HrVs2VKvvfaaunfvrqFDh2rq1KlasmSJ1aWFnK1bt2rOnDl65ZVXtHfvXq1du1YbNmzQc889Z3VpuEb03NRQ8+bNFRYWpvz8/Er78/Pz1apVq2qPadWqlU/tUbvrXOHFF1/U3Llz9d5776lr167+LDPo+Xqdjx49qmPHjik1NdW7z+PxSJLCw8P12WefqV27dv4tOgjV5s9zfHy8IiIiFBYW5t138803Ky8vT+Xl5YqMjPRrzcGqNtf62Wef1fDhw/XYY49Jkrp06aKysjKNHTtWU6dOld3O//9fq8v9HoyJifFbr41Ez02NRUZGqnv37srIyPDu83g8ysjIUO/evas9pnfv3pXaS9KWLVsu2x61u86SNG/ePD333HPatGmTevToEYhSg5qv17ljx47av3+/MjMzvdsDDzygu+66S5mZmXI6nYEsP2jU5s9znz59dOTIEW94lKRDhw4pPj6eYHMFtbnWZ8+erRJgKkKlwZOJTGHZ70G/TlcOMatXrzYcDoexYsUK48CBA8bYsWONJk2aGHl5eYZhGMbw4cONyZMne9t//PHHRnh4uPHiiy8aBw8eNKZPn85S8Brw9TrPnTvXiIyMNNasWWOcPHnSu5WUlFj1FYKCr9f521gtVTO+XuecnByjcePGxoQJE4zPPvvMePfdd42WLVsazz//vFVfIWj4eq2nT59uNG7c2PjDH/5gZGVlGX/729+Mdu3aGUOGDLHqK9R5JSUlxr59+4x9+/YZkowFCxYY+/btM44fP24YhmFMnjzZGD58uLd9xVLwX/7yl8bBgweNxYsXsxS8Lnr55ZeNG264wYiMjDR69uxp/P3vf/e+d+eddxojR46s1P7tt982OnToYERGRhq33HKLsWHDhgBXHJx8uc5t2rQxJFXZpk+fHvjCg4yvf56/iXBTc75e508++cTo1auX4XA4jLZt2xqzZ882Lly4EOCqg5Mv1/r8+fPGjBkzjHbt2hlRUVGG0+k0nnjiCeO///1v4AsPEh988EG1f99WXNeRI0cad955Z5VjunXrZkRGRhpt27Y1li9f7vc6eSo4AAAIKcy5AQAAIYVwAwAAQgrhBgAAhBTCDQAACCmEGwAAEFIINwAAIKQQbgAAQEgh3AAAgJBCuAFQLyQmJmrhwoVWlwGEtO3btys1NVUJCQmy2Wxav369T8fPmDFDNputytaoUSOfPodwA8B0jzzyiAYNGiRJ6tevn5566qmAnXvFihVq0qRJlf27du3S2LFjA1YHUB+VlZUpKSlJixcvrtXxkyZN0smTJyttnTp10k9+8hOfPodwAyAolJeXX9PxLVq0UMOGDU2qBkB1BgwYoOeff14/+tGPqn3f5XJp0qRJat26tRo1aqRevXpp69at3vejo6PVqlUr75afn68DBw7o0Ucf9akOwg0Av3nkkUe0bds2/fa3v/V2Lx87dkyS9K9//UsDBgxQdHS04uLiNHz4cBUUFHiP7devnyZMmKCnnnpKzZs3V//+/SVJCxYsUJcuXdSoUSM5nU498cQTKi0tlSRt3bpVo0aNUlFRkfd8M2bMkFR1WConJ0cDBw5UdHS0YmJiNGTIEOXn53vfnzFjhrp166bf/e53SkxMVGxsrH7605+qpKTE22bNmjXq0qWLGjRooOuuu04pKSkqKyvz09UEgt+ECRO0Y8cOrV69Wv/85z/1k5/8RD/4wQ90+PDhatu//vrr6tChg/r27evTeQg3APzmt7/9rXr37q0xY8Z4u5idTqcKCwt19913Kzk5Wbt379amTZuUn5+vIUOGVDp+5cqVioyM1Mcff6wlS5ZIkux2u1566SX9+9//1sqVK/X+++/rV7/6lSTp9ttv18KFCxUTE+M936RJk6rU5fF4NHDgQJ05c0bbtm3Tli1blJWVpaFDh1Zqd/ToUa1fv17vvvuu3n33XW3btk1z586VJJ08eVIPPfSQRo8erYMHD2rr1q0aPHiweBYxUL2cnBwtX75cf/zjH9W3b1+1a9dOkyZN0h133KHly5dXaX/u3DmtWrXK514bSQo3o2AAqE5sbKwiIyPVsGFDtWrVyrt/0aJFSk5O1pw5c7z7li1bJqfTqUOHDqlDhw6SpO985zuaN29epc/85vydxMREPf/88xo3bpxeeeUVRUZGKjY2VjabrdL5vi0jI0P79+9Xdna2nE6nJOnNN9/ULbfcol27dum73/2upIshaMWKFWrcuLEkafjw4crIyNDs2bN18uRJXbhwQYMHD1abNm0kSV26dLmGqwWEtv3798vtdnv/+67gcrl03XXXVWm/bt06lZSUaOTIkT6fi3ADIOD+8Y9/6IMPPlB0dHSV944ePer9y6979+5V3n/vvfeUnp6u//znPyouLtaFCxd07tw5nT17tsZzag4ePCin0+kNNpLUqVMnNWnSRAcPHvSGm8TERG+wkaT4+HidOnVKkpSUlKTvf//76tKli/r37697771XDz74oJo2bVrzCwHUI6WlpQoLC9OePXsUFhZW6b3q/i54/fXX9cMf/lBxcXE+n4thKQABV1paqtTUVGVmZlbaDh8+rO9973vedt9e/nns2DH98Ic/VNeuXfWnP/1Je/bs8a7KuNYJx9WJiIio9Npms8nj8UiSwsLCtGXLFv31r39Vp06d9PLLL+umm25Sdna26XUAoSA5OVlut1unTp1S+/btK23f7mnNzs7WBx98UKshKYmeGwB+FhkZKbfbXWnfrbfeqj/96U9KTExUeHjN/xras2ePPB6P5s+fL7v94v+bvf3221c937fdfPPNys3NVW5urrf35sCBAyosLFSnTp1qXI/NZlOfPn3Up08fTZs2TW3atNG6deuUlpZW488AQklpaamOHDnifZ2dna3MzEw1a9ZMHTp00MMPP6wRI0Zo/vz5Sk5O1unTp5WRkaGuXbvq/vvv9x63bNkyxcfHa8CAAbWqg54bAH6VmJioTz/9VMeOHVNBQYE8Ho/Gjx+vM2fO6KGHHtKuXbt09OhRbd68WaNGjbpiMGnfvr3Onz+vl19+WVlZWfrd737nnWj8zfOVlpYqIyNDBQUFOnv2bJXPSUlJUZcuXfTwww9r79692rlzp0aMGKE777xTPXr0qNH3+vTTTzVnzhzt3r1bOTk5Wrt2rU6fPq2bb77ZtwsEhJDdu3crOTlZycnJkqS0tDQlJydr2rRpkqTly5drxIgR+sUvfqGbbrpJgwYN0q5du3TDDTd4P6NirtsjjzxSZfiqpgg3APxq0qRJCgsLU6dOndSiRQvl5OQoISFBH3/8sdxut+6991516dJFTz31lJo0aeLtkalOUlKSFixYoBdeeEGdO3fWqlWrlJ6eXqnN7bffrnHjxmno0KFq0aJFlQnJ0sUelz//+c9q2rSpvve97yklJUVt27bVW2+9VePvFRMTo+3bt+u+++5Thw4d9Mwzz2j+/Pm1/j9NIBT069dPhmFU2VasWCHp4lDvzJkzlZ2drfLycp04cUJr166tNBnfbrcrNzdXs2fPrnUdNoN1iwAAIITQcwMAAEIK4QYAAIQUwg0AAAgphBsAABBSCDcAACCkEG4AAEBIIdwAAICQQrgBAAAhhXADAABCCuEGAACEFMINAAAIKYQbAAAQUv4fzgSUomuzzzsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLotting the loss values for every training iterations\n",
    "loss_plot = [loss_hist[i] for i in range(len(loss_hist))]\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss function\")\n",
    "plt.plot(loss_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation:\n",
      "Mean Squared Error (MSE): 248137246.11\n",
      "R-squared (R²): -578.73\n",
      "Model Coefficients:\n",
      "age: 12167.37\n",
      "sex: -0.12\n",
      "bmi: 11966.88\n",
      "children: 2690.38\n",
      "smoker: 23693.39\n",
      "region: -1145.82\n",
      "\n",
      "Model coefficients saved to 'model_coefficients.csv'.\n"
     ]
    }
   ],
   "source": [
    "m = (X_test).shape[0]\n",
    "y_matrix = (y_test).reshape((m,1))\n",
    "y_pred = np.dot((X_test), w.T) + b\n",
    "\n",
    "# Evaluate the Model\n",
    "# 1. Mean Squared Error (MSE)\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "\n",
    "# 2. R-squared (R²)\n",
    "y_mean = np.mean(y_test)  # Mean of actual values\n",
    "ss_res = np.sum((y_test - y_pred) ** 2)  # Residual Sum of Squares\n",
    "ss_tot = np.sum((y_test - y_mean) ** 2)  # Total Sum of Squares\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(f\"Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")\n",
    "\n",
    "# Reshape w if necessary to ensure it's a 1D array\n",
    "w_coeff = np.array(w).flatten()\n",
    "\n",
    "# Feature names\n",
    "feature_names = data.drop(columns=['charges']).columns\n",
    "\n",
    "# Analyze Model Coefficients\n",
    "print(\"Model Coefficients:\")\n",
    "for feature, coef in zip(feature_names, w_coeff):\n",
    "    print(f\"{feature}: {coef:.2f}\")\n",
    "\n",
    "# Optionally save coefficients to a file\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': w_coeff\n",
    "})\n",
    "coefficients_df.to_csv('./model_coefficients.csv', index=False)\n",
    "print(\"\\nModel coefficients saved to 'model_coefficients.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "K2QuEbE1Clxq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   age     sex     bmi  children smoker     region      charges\n",
      "0   19  female  27.900         0    yes  southwest  16884.92400\n",
      "1   18    male  33.770         1     no  southeast   1725.55230\n",
      "2   28    male  33.000         3     no  southeast   4449.46200\n",
      "3   33    male  22.705         0     no  northwest  21984.47061\n",
      "4   32    male  28.880         0     no  northwest   3866.85520\n",
      "\n",
      "Data types of each column:\n",
      "age           int64\n",
      "sex          object\n",
      "bmi         float64\n",
      "children      int64\n",
      "smoker       object\n",
      "region       object\n",
      "charges     float64\n",
      "dtype: object\n",
      "\n",
      "Summary statistics:\n",
      "               age          bmi     children       charges\n",
      "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
      "mean     39.207025    30.663397     1.094918  13270.422265\n",
      "std      14.049960     6.098187     1.205493  12110.011237\n",
      "min      18.000000    15.960000     0.000000   1121.873900\n",
      "25%      27.000000    26.296250     0.000000   4740.287150\n",
      "50%      39.000000    30.400000     1.000000   9382.033000\n",
      "75%      51.000000    34.693750     2.000000  16639.912515\n",
      "max      64.000000    53.130000     5.000000  63770.428010\n",
      "\n",
      "Checking for missing values:\n",
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "\n",
      "Dataset after handling missing values:\n",
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n",
      "\n",
      "Encoding categorical variables...\n",
      "\n",
      "Data after encoding:\n",
      "   age  sex     bmi  children  smoker  region      charges\n",
      "0   19    0  27.900         0       1       3  16884.92400\n",
      "1   18    1  33.770         1       0       2   1725.55230\n",
      "2   28    1  33.000         3       0       2   4449.46200\n",
      "3   33    1  22.705         0       0       1  21984.47061\n",
      "4   32    1  28.880         0       0       1   3866.85520\n",
      "\n",
      "Shape of X (features): (1338, 6)\n",
      "Shape of y (target): (1338,)\n",
      "\n",
      "Processed data saved to ./processed_data1.csv.\n",
      "Shape of X_train:  (1003, 6) Shape of y_train:  (1003,)\n",
      "Shape of X_test:  (335, 6) Shape of y_test:  (335,)\n",
      "Iteration 0: Loss = 163236603.0038235\n",
      "Iteration 100000: Loss = 18181498.272036385\n",
      "Iteration 200000: Loss = 18166145.096072234\n",
      "Iteration 300000: Loss = 18166006.94557185\n",
      "Iteration 400000: Loss = 18166005.701570354\n",
      "Iteration 500000: Loss = 18166005.6903685\n",
      "Iteration 600000: Loss = 18166005.69026763\n",
      "Iteration 700000: Loss = 18166005.69026672\n",
      "Iteration 800000: Loss = 18166005.690266717\n",
      "Iteration 900000: Loss = 18166005.690266714\n",
      "Updated w_manual [[ 1.21673691e+04 -1.20372704e-01  1.19668834e+04  2.69037902e+03\n",
      "   2.36933927e+04 -1.14582154e+03]]\n",
      "Updated b_manual -2022.8660366185754\n",
      "Train Error manual:  18166005.690266717 , Test Error manual:  18624397.326823644\n",
      "Model Evaluation:\n",
      "Mean Squared Error (MSE): 248137246.11\n",
      "R-squared (R²): -578.73\n",
      "Model Coefficients:\n",
      "age: 12167.37\n",
      "sex: -0.12\n",
      "bmi: 11966.88\n",
      "children: 2690.38\n",
      "smoker: 23693.39\n",
      "region: -1145.82\n",
      "\n",
      "Model coefficients saved to 'model_coefficients1.csv'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Manually choose the hyperparameters (learning rate and number of features) and train the model.\n",
    "Then compare the performance with random chosen hyperparameters and manually chosen hyperparameters.\n",
    "\"\"\"\n",
    "r = 6   \n",
    "alpha_manual = 0.001\n",
    "num_iters = 1000000\n",
    "\n",
    "# Load the dataset\n",
    "filepath = './data_insurance.csv'  # Ensure this file is in your working directory\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "# 1. Explore the Data\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "print(\"\\nData types of each column:\")\n",
    "print(data.dtypes)\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# 2. Handle Missing Data\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "# For numerical columns, fill missing values with the column's mean\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_columns:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "# For categorical columns, fill missing values with the most frequent value\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "print(\"\\nDataset after handling missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 3. Convert Categorical Variables\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "\n",
    "# Encode 'sex' and 'smoker' using Label Encoding\n",
    "label_encoders = {}  # Dictionary to store label encoders for reference\n",
    "for column in ['sex', 'smoker']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Encode 'region' using Label Encoding (assigns numeric labels to categories)\n",
    "region_le = LabelEncoder()\n",
    "data['region'] = region_le.fit_transform(data['region'])\n",
    "\n",
    "print(\"\\nData after encoding:\")\n",
    "print(data.head())\n",
    "\n",
    "# 4. Define Features and Target\n",
    "X = data.drop(columns=['charges']).values  # Independent variables\n",
    "y = data['charges'].values                 # Dependent variable\n",
    "\n",
    "print(\"\\nShape of X (features):\", X.shape)\n",
    "print(\"Shape of y (target):\", y.shape)\n",
    "\n",
    "# Save processed data if needed\n",
    "processed_filepath = './processed_data1.csv'\n",
    "data.to_csv(processed_filepath, index=False)\n",
    "print(f\"\\nProcessed data saved to {processed_filepath}.\")\n",
    "\n",
    "X_new = min_max_scaler(X)\n",
    "X_train_manual, X_test_manual, y_train_manual, y_test_manual = train_test_split(X_new, y, test_size=0.25, random_state=42)\n",
    "print(\"Shape of X_train: \",X_train_manual.shape, \"Shape of y_train: \",y_train_manual.shape)\n",
    "print(\"Shape of X_test: \",X_test_manual.shape, \"Shape of y_test: \",y_test_manual.shape)\n",
    "initial_w = np.random.randn(1, r)\n",
    "initial_b = np.random.randn()\n",
    "w_manual,b_manual,loss_hist_manual = batch_gradient_descent(X_train_manual,y_train_manual,initial_w,initial_b,alpha_manual,num_iters)\n",
    "print(\"Updated w_manual\",w_manual)\n",
    "print(\"Updated b_manual\",b_manual)\n",
    "train_error_manual = loss_function(X_train_manual,y_train_manual,w_manual,b_manual)\n",
    "test_error_manual = loss_function(X_test_manual,y_test_manual,w_manual,b_manual)\n",
    "print(\"Train Error manual: \",train_error_manual, \", Test Error manual: \",test_error_manual)\n",
    "\n",
    "m = (X_test).shape[0]\n",
    "y_matrix = (y_test).reshape((m,1))\n",
    "y_pred = np.dot((X_test), w.T) + b\n",
    "\n",
    "# Evaluate the Model\n",
    "# 1. Mean Squared Error (MSE)\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "\n",
    "# 2. R-squared (R²)\n",
    "y_mean = np.mean(y_test)  # Mean of actual values\n",
    "ss_res = np.sum((y_test - y_pred) ** 2)  # Residual Sum of Squares\n",
    "ss_tot = np.sum((y_test - y_mean) ** 2)  # Total Sum of Squares\n",
    "r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(f\"Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")\n",
    "\n",
    "# Reshape w if necessary to ensure it's a 1D array\n",
    "w_coeff = np.array(w).flatten()\n",
    "\n",
    "# Feature names\n",
    "feature_names = data.drop(columns=['charges']).columns\n",
    "\n",
    "# Analyze Model Coefficients\n",
    "print(\"Model Coefficients:\")\n",
    "for feature, coef in zip(feature_names, w_coeff):\n",
    "    print(f\"{feature}: {coef:.2f}\")\n",
    "\n",
    "# Optionally save coefficients to a file\n",
    "coefficients_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': w_coeff\n",
    "})\n",
    "coefficients_df.to_csv('./model_coefficients1.csv', index=False)\n",
    "print(\"\\nModel coefficients saved to 'model_coefficients1.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
